slug: nvidia-triton
description: |
  ## Why monitor NVIDIA Triton?
  Monitoring helps ensure that your Triton server is running optimally. By tracking metrics like GPU utilization, memory usage, and inference latency, you can identify bottlenecks and fine-tune your server configuration for better performance.
  
  ## Comprehensive monitoring quickstart for NVIDIA Triton
  The Triton Inference Server offers optimized performance for a wide range of query types, such as real-time, batched, ensembles, and audio/video streaming. As a component of the NVIDIA AI Enterprise software platform, it plays a vital role in accelerating the data science pipeline and simplifying the development and deployment of AI solutions in production environments.

  ## Whatâ€™s included in this quickstart?
  New Relic NVIDIA Triton monitoring quickstart ability to cover quality on out-of-the-box reporting.
  - Monitoring and Management
  - Scaling and Optimization
  - Documentation and Support
  - Dashboards
  - Alerts

summary: |
   Monitor and analyze your NVIDIA Triton infrastructure with New Relic.
icon: logo.png
level: New Relic
authors:
  - New Relic
  - Praveen Kudikyala
title: NVIDIA Triton
documentation:
  - name: NVIDIA Triton integration documentation
    description: |
      Monitor and instrument your NVIDIA Triton with New Relic to gain deep insights into your performance.
    url: https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/nvidia-triton-integration/
keywords:
  - NVIDIA Triton inference server
  - AI Acceleration
  - Machine Learning Acceleration
  - GPU Management
  - AI Management
  - Machine Learning Management
  - Deep Learning Performance
  - AI Performance
  - GPU Optimization
  - AI Optimization
  - inference server
  - NR1_addData
  - NR1_sys
dataSourceIds:
  - nvidia-triton
dashboards:
  - nvidia-triton
alertPolicies:
  - nvidia-triton